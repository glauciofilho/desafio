Desafio TÃ©cnico â€“ Analytics Engineer SÃªnior

ğŸ¯ Pipeline de Dados com Airflow + Snowflake

Este desafio tÃ©cnico simula uma situaÃ§Ã£o real onde uma empresa precisa consolidar dados de vendas, CRM e marketing diariamente, utilizando uma arquitetura escalÃ¡vel e confiÃ¡vel.



Seu objetivo serÃ¡ construir uma DAG no Airflow para orquestrar esse pipeline e realizar cargas diÃ¡rias no Snowflake.

ğŸ§ª DescriÃ§Ã£o do Desafio

VocÃª trabalharÃ¡ com dados simulados em formato CSV ou JSON representando trÃªs fontes distintas: CRM, faturas e campanhas de e-mail.



Sua responsabilidade Ã© garantir a ingestÃ£o, transformaÃ§Ã£o e carga desses dados em Snowflake, com validaÃ§Ã£o de sucesso e alertas em caso de falha.

ğŸ”§ EntregÃ¡veis TÃ©cnicos

- DAG no Apache Airflow com as seguintes tarefas:

  - IngestÃ£o dos arquivos (pode ser leitura local ou bucket)

  - Limpeza e validaÃ§Ã£o dos dados (pode usar Pandas ou SQL)

  - Carga final no Snowflake em tabelas normalizadas

- Implementar lÃ³gica de dependÃªncia entre as tarefas (sequencial e paralela onde fizer sentido)

- Simular alertas por e-mail/log em caso de falhas

- Tabelas criadas devem conter schemas padronizados (nomes, tipos e chaves primÃ¡rias/estrangeiras)

âœ¨ Extras que contam pontos

- Uso de task groups para organizaÃ§Ã£o

- Uso de macros ou templates no Airflow

- ValidaÃ§Ã£o de schema dos arquivos antes de carga

- DocumentaÃ§Ã£o das tarefas no cÃ³digo e no README

- Pipeline executÃ¡vel via Docker Compose

âš  Importante

VocÃª pode mockar os dados (ex: CSVs gerados manualmente ou com Faker).



NÃ£o Ã© necessÃ¡rio realizar deploy real em ambiente de produÃ§Ã£o ou configurar autenticaÃ§Ã£o robusta. Foque em:

- Clareza da DAG

- Estrutura de cÃ³digo e organizaÃ§Ã£o

- Boas prÃ¡ticas de engenharia de dados

ğŸ“¦ Entrega esperada

- RepositÃ³rio no GitHub com:

  - CÃ³digo do Airflow

  - Scripts de transformaÃ§Ã£o se aplicÃ¡vel

  - Arquivo docker-compose.yml (opcional)

  - README.md com instruÃ§Ãµes de execuÃ§Ã£o e estrutura de tabelas

- Prints ou link de dashboard (Airflow UI ou estrutura Snowflake)

ğŸ•’ InstruÃ§Ãµes Finais

Prazo para entrega: 3 dias corridos

Tempo estimado de execuÃ§Ã£o: entre 6 a 8 horas

NÃ­vel de dificuldade: SÃªnior



Este teste visa avaliar sua habilidade de estruturar pipelines confiÃ¡veis, com boa organizaÃ§Ã£o de tarefas e visÃ£o de arquitetura de dados.



Capriche no README e aproveite a chance de mostrar sua senioridade! ğŸš€